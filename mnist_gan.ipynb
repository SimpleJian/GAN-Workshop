{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hacks to avoid using the gpu if you have one \n",
    "# import os \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "Accompanying the [ML@B](https://ml.berkeley.edu) Fall Workshop on Generative Adversarial Networks. Original code from https://github.com/jacobgil/keras-dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE=0.0005\n",
    "BETA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model(): \n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(input_dim=100, units=1024))\n",
    "    generator.add(Activation('tanh'))\n",
    "    generator.add(Dense(128*7*7))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Activation('tanh'))\n",
    "    generator.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    generator.add(UpSampling2D(size=(2, 2)))\n",
    "    generator.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    generator.add(Activation('tanh'))\n",
    "    generator.add(UpSampling2D(size=(2, 2)))\n",
    "    generator.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    generator.add(Activation('tanh'))\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(\n",
    "            Conv2D(64, (5, 5),\n",
    "            padding='same',\n",
    "            input_shape=(28, 28, 1))\n",
    "            )\n",
    "    discriminator.add(Activation('tanh'))\n",
    "    discriminator.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    discriminator.add(Conv2D(128, (5, 5)))\n",
    "    discriminator.add(Activation('tanh'))\n",
    "    discriminator.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1024))\n",
    "    discriminator.add(Activation('tanh'))\n",
    "    discriminator.add(Dense(1))\n",
    "    discriminator.add(Activation('sigmoid'))\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('samples'):\n",
    "    os.makedirs('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train[:, :, :, None]\n",
    "X_test = X_test[:, :, :, None]\n",
    "# X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "d = discriminator_model()\n",
    "g = generator_model()\n",
    "d_on_g = generator_containing_discriminator(g, d)\n",
    "d_optim = Adam(lr=LEARNING_RATE, beta_1=BETA)\n",
    "g_optim = Adam(lr=LEARNING_RATE, beta_1=BETA)\n",
    "g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "d.trainable = True\n",
    "d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "for epoch in range(100):\n",
    "    print(\"Epoch is\", epoch)\n",
    "    print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "    for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "        noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "        image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "        generated_images = g.predict(noise, verbose=0)\n",
    "        if index % 20 == 0:\n",
    "            image = combine_images(generated_images)\n",
    "            image = image*127.5+127.5\n",
    "            Image.fromarray(image.astype(np.uint8)).save(\n",
    "                 'samples/'+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "        d_loss = d.train_on_batch(X, y)\n",
    "#         print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        d.trainable = False\n",
    "        g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "        d.trainable = True\n",
    "        sys.stdout.write('\\r'+\"batch%d  d_loss: %f; g_loss : %f\" % (index, d_loss, g_loss))\n",
    "        if index % 10 == 9:\n",
    "            g.save_weights('generator', True)\n",
    "            d.save_weights('discriminator', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_image(img):\n",
    "    plt.axis('off')\n",
    "#     plt.figure(dpi = 100)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False, gen_model='generator', disc_model='discriminator'):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights(gen_model)\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights(disc_model)\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_image(generate(20, nice=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the turkey that's already in the oven\n",
    "# display_image(generate(20, nice=False, gen_model='good_gen', disc_model='good_disc' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
